---
title: "Module 4: AI For Medicine"
author: "Teddy HLA"
format: revealjs
---

## Module 4 Learning Objectives {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Appreciate machine learning vs. AI
- Understand the high-level steps needed to train a statistical model
- Rationale for "verifying your model findings" and how to use a test set
- Understand dataset bias and clinical factors

---

## Scenario 1 {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- You are a *GP*.
- You use an AI-based clinical decision support (CDS) tool to help manage patients with "breast lump" presentations.
- The tool helps decide amongst options: **invasive investigation**, **imaging**, or **watchful waiting**.
- A 17-year-old male patient presents with a "breast lump."
- Should you *trust* the model recommendations for this patient?

---

## Scenario 2 {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- You are a *clinical lead* for your organization.
- You want to improve pathways for acutely unwell patients.
- You have a **100,000 GBP** budget for this.
- Your team presents two options:
  - Option 1: Recruit **two specialist nurses**
  - Option 2: Deploy an **AI-based CDS and risk management system**

- Which option would you choose?

---

## Big Data, Machine Learning, and Artificial Intelligence {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Big data → ML/AI
- The six **Vs** of big data: **volume**, **variety**, **velocity**, **veracity**, **value**, and **variability**
- I would like to add **vulnerability**

---

## Machine Learning vs. Artificial Intelligence {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Four types of machine learning:
  - Supervised learning
  - Unsupervised learning
  - Deep Learning (e.g., image recognition)
  - Reinforcement Learning
- Rule of thumb:
  - If the model only lives on your computer, it’s a **ML model**.
  - If it's deployed for clinician use, it’s **AI**.

---

## Machine Learning Process {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

![](/media/daim/module_4/mleng.jpg)

---

## Complexity of the Model {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

* In ML, you need to trade off between **bias** and **variance**:
  + Very biased model = assuming everyone is sick
  + High variant model = responding to every noise

![](/media/daim/module_4/biasvariance.jpg)

---

## Appreciate {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

![](/media/daim/module_4/aimlstats.jpg)

---

![](/media/daim/module_4/mleng.jpg)

---

## MLOps : steps in ML {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Get the data, Train the model, Evaluate the model!
- WIN :
- Getting the data onto your computer
- Train the model on your computer
- Show to your boss, publish!  

**Right??**

---

## Machine Learning and Philosophy of Learning {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- **Learning?** Why do we learn?
- Difference between learning and memorizing
- What does it mean mathematically?
- What does training mean for you and for a machine learning model?

---

## Learning vs. Memorizing {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

Using an example of **adding and the symbol +**:

- You learn to add and use the symbol **+**
- This allows you to *generalize* rather than memorizing specific sums, like `1002 + 2003 = 3005`
- You *train* by practicing simple exercises like `1 + 1 = 2`
- Your teacher corrects if you get `1 + 1 = 3`
- You are then examined on new material to ensure you can generalize and apply your learnings

- **Similarly:** You use a **training dataset** to train the model so it can *learn* and apply in a **general** context.

---

## What does learning mean for a computer? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

$$
Y = f(x)
$$

- Find function **f(x)** given a set of variables (**x**) and their outcomes (**Y**) using a training dataset
  - **Loss function** = similar to making mistakes on training
  - **Optimizer** = acts like a teacher, with the goal to minimize the loss function

---

## How does the optimiser make the network "learn"? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- A common analogy is one of a ball rolling down a hill.
- The height of the hill (z) represents the loss function, and the two other directions (x, y) are model parameters

## How does the optimiser make the network "learn"? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- The "ball" (the model) rolls down the hill to find the value of the two values that minimises the loss.
- This is called **gradient descent**.

## How does the optimiser make the network "learn"? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- The animation demonstrates the process for 2 parameters (x, y) in 2D.
- Machine learning models have **100,000s** of parameters.
- It's difficult to visualise a ball rolling around in a million dimensional space!

## Machine Learning Process {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

![](/media/daim/module_4/mleng.jpg)

---

## Complexity of Model {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- In ML, trade-offs exist between **bias** and **variance**:
  - A **very biased model** may assume everyone is sick
  - A **high variance model** may respond to every noise

![](/media/daim/module_4/biasvariance.jpg)

---

## Appreciating AI, ML, and Statistics {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

![](/media/daim/module_4/aimlstats.jpg)

---

## The MLOps Lifecycle {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- **MLOps** = Machine Learning + Operations
- Key stages include:
  - **ETL pipeline**: Extract, Transform, and Load data
  - **Train the model**: Run computations to optimize model performance
  - **Deploy the model**: Serve it to users in real-time, with continuous deployment

---

## Evaluate Your Model: How? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Validation is key to model reliability:
  - **Training set validation** = marking your own homework!
  - **Test set validation** = using a separate, fresh dataset
- Beware of **data leakage**

---

## Understanding Data Leakage {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

Example of data leakage in Chest X-Ray (CXR) data:

- Suppose a model is trained to detect pneumonia
  - Sicker patients often get **AP films** and are placed in **resus**
  - The model might "cheat" by detecting **resus environment** instead of pneumonia itself

![](/media/daim/module_4/chest.jpg)

---

## Gold Standards in Medical AI {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Refer to [this BMJ article on standards](https://www.bmj.com/content/384/bmj-2023-074821)
- Also, see [related BMJ content](https://www.bmj.com/content/384/bmj-2023-074819)

![](/media/daim/module_4/extvali.jpg)

---

## Ethics of AI {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- The ethics of AI/ML are complex:
  - Should generative AI models (like ChatGPT) be allowed in research writing?
  - Should clinical judgments rely on AI recommendations?

- **AI/ML don’t always get it right**, but neither do humans
  - Does AI/ML need to be better than humans?
  - Which humans: FY1 or an average consultant?

---

## Examples of 'Bad' AI {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- "AI Gaydar Paper" (Wang 2018)

![](/media/daim/module_4/aigaydar.jpg)

---

## How Do We ~~Do Good~~ *Stop Bad* AI? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Recognize inherent biases and discrimination
- Assume bias is present, then find and address it
- Maximize individual autonomy and privacy
- Reproducibility and transparency are crucial

![](/media/daim/module_4/turingway.jpg)

---

## Even if AI is Good? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}


![](/media/daim/module_4/inequality.jpeg){#fig-inequality}

**NHS app and deprivation:** See [this study](https://informatics.bmj.com/content/30/1/e100809)

---

## Reproducibility: An Analogy  {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

::: {#fig-elephants layout-ncol=2}

![](/media/daim/module_4/kitchen.jpg){#fig-kitchen}

![](recipe.jpg){#fig-recipe}

**Kitchen and Recipe**

:::

---

## Reproducibility: Important Questions  {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- What type of oven?
- What mode: fan or gas?
- Which oil: olive oil or rapeseed?
- Type of milk?

In ML: consider details like **Python version** and **framework**

---

## Real-Life Example  {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}


![](/media/daim/module_4/neupane_table1.png)

**Different OSs parse data differently**  
Reference: Bhandari Neupane et al., "Characterization of Leptazolines a–d" (2019)

---

## Reproducibility Analogy  {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}


![](/media/daim/module_4/repro.jpg)

---

## How to Make Research Reproducible  {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}


- Aim for reproducibility, even if it’s challenging at first
- Visit [RAPS with R](https://raps-with-r.dev/) for reproducibility principles

---

## Scenario 1 Revisited  {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- You are a *GP*. 
- You use an AI-based clinical decision support (CDS) tool to help manage patients with "breast lump" presentations.
- The tool suggests options like **invasive investigation**, **imaging**, or **watchful waiting**.
- A 17-year-old male patient presents with a "breast lump."

- **Question**: Should you *trust* the model's recommendations for this patient?

---

### Scenario 1: Critical Questions  {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Was the AI CDS trained on both male and female images?
- Were patients under 18 included in the training set?
- Is the model optimized for **sensitivity** or **specificity**?
- What does your clinical judgment suggest?
- What are the local governance policies regarding AI use?

---

## Scenario 2 Revisited {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- You are a *clinical lead* for your organization.
- Your goal is to improve pathways for acutely unwell patients.
- You have a **100,000 GBP** budget.

- Two options are presented:
  - **Option 1**: Recruit **two specialist nurses**
  - **Option 2**: Deploy an **AI-based CDS and risk management system**

- **Question**: Which option would you choose?

---

### Scenario 2: Considerations {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}


- **Nurses**:
  - Would they provide versatility and fill in during staff shortages?
  - Would they be happy in their roles, or might they leave?

- **AI System**:
  - Does your organization have the digital infrastructure for AI?
  - Are clinical pathways aligned with AI integration?
  - If AI flags deterioration, can your pathways respond effectively?
  - AI offers scalability and continuous availability, but what if it fails?

---

## A Word on Technical Debt {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}


- Even Google has significant technical debt
- The NHS may have even more due to legacy systems and infrastructure

- **Reference**: [Google’s Technical Debt Paper](https://research.google.com/pubs/archive/43146.pdf)

![](/media/daim/module_4/dependency_2x.png)

---

## Summary of Key Concepts {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- **ML vs. AI**:
  - ML models remain on your computer; AI models are deployable.
- **MLOps Workflow**:
  - Extract, Transform, Load → Train models → Serve and Evaluate.
- **Model Evaluation**:
  - Test model outputs on an independent test set for validation.
- **AI Ethics and Reproducibility**:
  - Prioritize transparency, address biases, and ensure reproducibility in AI applications.

---

## Further Reading and Resources {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}


- For reproducibility guidelines, see [The Turing Way](https://the-turing-way.netlify.app/)
- More on big data ethics: [Data Ethics Framework](https://www.gov.uk/government/publications/data-ethics-framework)

---

## Discussion and Q&A {background-image="/media/daim/coffee1.png" background-opacity="0.6" text-align=center}

- Let’s discuss any remaining questions on ML/AI in clinical applications!


