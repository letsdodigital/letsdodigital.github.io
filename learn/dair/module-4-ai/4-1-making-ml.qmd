---
title: "AI: Making an ML Model"
author: "DAIM Team"
format: revealjs
logo: /media/ldd-logo.png
css: /slides.css
title-slide-attributes: 
  data-background-image: /media/daim/bg_cubes_blue.png
  data-background-opacity: "0.6"
---


## Module 4: Part 1 Learning Objectives {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Appreciate machine learning vs. AI
- Understand the high-level steps needed to train a statistical model
- Rationale for "verifying your model findings" and how to use a test set
- Understand dataset bias and clinical factors

---

## What is machine learning?

* TODO Understand what machine learning is at a broad level (LL2)

## Big Data, Machine Learning, and Artificial Intelligence {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Big data â†’ ML/AI
- The six **Vs** of big data: **volume**, **variety**, **velocity**, **veracity**, **value**, and **variability**
- I would like to add **vulnerability**

## Machine Learning vs. Artificial Intelligence {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- There are no set, global definitions for either term!
- Machine learning often refers to a **specific subset of statistical algorithms**
    - Artificial neural networks
    - Decision trees
    - Support vector machines
    - And more - **it is a loose category**

## Machine Learning vs. Artificial Intelligence {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Different types of machine learning:
    - Supervised learning
    - Unsupervised learning
    - Reinforcement Learning
- Deep Learning refers to neural networks with **multiple layers**
    - We will be building one in the workshop

## Supervised / Unsupervised Learning {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Supervised learning uses **labelled data**.
    - For instance, a radiologist has **labelled** CT head studies with different types of **intracranial haemorrhage**, and the **ML system learns** which scans contain which type of haemorrhage. 

TODO: find image

## Supervised / Unsupervised Learning {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- Unsupervised learning uses **unlabelled data**
    - For instance, an ML system is given a series of **normal chest radiographs** and learns how best to **compress and uncompress** them.
    - This is known as an **autoencoder.**

TODO: find image

## Appreciate {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

![](/media/daim/module_4/aimlstats.jpg)

**Right??**

#
:::{.r-stack}
**How to train an ML model**
:::

## What steps are needed to train a machine learning model? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- **Collecting** or **identifying** a dataset
- **Partitioning** a dataset into groups 
- **Preprocessing** your dataset
- Designing the **architecture** of the model
- **Training** the model
- **Evaluating** the model
- **Deploying** the model

## Machine Learning Process {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

![](/media/daim/module_4/mleng.jpg)

--- 

## The MLOps Lifecycle {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- **MLOps** = Machine Learning + Operations
- Key stages include:
  - **ETL pipeline**: Extract, Transform, and Load data
  - **Train the model**: Run computations to optimize model performance
  - **Deploy the model**: Serve it to users in real-time, with continuous deployment

## How do you split up a dataset?

- A dataset is typically split into three parts
    1. **Training data** (training the model)
    2. **Testing data** (testing the model after training)
    3. **Validation data** (testing the model during training)
- The reasons for this will be discussed over the course of these two seminars.

## Bias in a clinical dataset

* TODO - Understand dataset bias and clincial factors that can confound a dataset (LL4)
* TODO - Use examples to demonstrate clinical bias (LL4)
* TODO - Be able to list clinical uses for ML (LL4)

#
:::{.r-stack}
**How to preprocess data for an ML model?**
:::

## Data preprocessing 

- **Data preprocessing** refers to **optimising the data** in your dataset **for the model** that you have chosen to train.
- Different models have different formats which the data must be in
- Data is usually passed to the model as a NumPy array
    - You may see these referred to as **tensors**

## What kind of NumPy Array?

- This will depend on the type of data being used.
- For **images**, it is likely to be an image with certain:
    - **Dimensions** (e.g. `256 x 256`)
    - **Number of channels** (e.g. 1 or 3)
- We will **explore this further** in the workshop.

## What is data augmentation?

- Often, datasets are **small** and machine learning models need a **large amount of data** to be robust to **natural variations**.
- This includes changes in **brightness**, **contrast**, **rotation**, etc.
- This can be simulated in a dataset by varying these parameters for each image.

## Example of data augmentation

TODO create figure demonstrating modifying brightness, rotation and contrast for a chest radiograph.

## Going further than this...

- In imaging, further data augmentation techniques can be applied to **simulate anatomical variation**
- For instance, **elastic deformation**
- **Subtle image distortion** to **simulate** data acquired from a **different patient**.

TODO find image

## Data augmentation

- There are many **more techniques** that can be applied to extend a small dataset
- There are more techniques for **other types of data** (e.g. time series data).

## Break! {background-image="/media/daim/coffee1.png" background-opacity="0.6" text-align=center}

## The workshop task

* TODO Be able to relate the aims of the example task (Pneumonia detection task) (LL4)

## Machine Learning and Philosophy of Learning {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- **Learning?** Why do we learn?
- Difference between learning and memorizing
- What does it mean mathematically?
- What does training mean for you and for a machine learning model?

## Learning vs. Memorizing {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

Using an example of **adding and the symbol +**:

- You learn to add and use the symbol **+**
- This allows you to *generalize* rather than memorizing specific sums, like `1002 + 2003 = 3005`
- You *train* by practicing simple exercises like `1 + 1 = 2`
- Your teacher corrects if you get `1 + 1 = 3`
- You are then examined on new material to ensure you can generalize and apply your learnings

- **Similarly:** You use a **training dataset** to train the model so it can *learn* and apply in a **general** context.

## What does learning mean for a computer? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

$$
Y = f(x)
$$

- Find function **f(x)** given a set of variables (**x**) and their outcomes (**Y**) using a training dataset
  - **Loss function** = similar to making mistakes on training
  - **Optimizer** = acts like a teacher, with the goal to minimize the loss function

## How does the optimiser make the network "learn"? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- A common analogy is one of a ball rolling down a hill.
- The height of the hill (z) represents the loss function, and the two other directions (x, y) are model parameters

## How does the optimiser make the network "learn"? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- The "ball" (the model) rolls down the hill to find the value of the two values that minimises the loss.
- This is called **gradient descent**.

## How does the optimiser make the network "learn"? {background-image="/media/daim/bg_cubes_red_right.png" background-opacity="0.6"}

- The animation demonstrates the process for 2 parameters (x, y) in 2D.
- Machine learning models have **100,000s** of parameters.
- It's difficult to visualise a ball rolling around in a million dimensional space!

## Model Architecture and Training

- TODO Model architecture and training
    -   TODO Understand why ML frameworks exist in the Python ecosystem (TensorFlow, PyTorch) and what they allow the user to do (LL2)
    -   TODO Understand the inputs and outputs of a neural network (LL2)
    -   TODO Understand the difference between a convolutional layer and dense layer at a broad level (LL2)
    -   TODO Understand what an epoch of training is (LL2)
    -   TODO Understand why data needs to be batched when training a network (LL3)
    -   TODO Understand what a sigmoid layer is and why it is used for probabilistic outputs (LL2)

# Hyperparameters

-   TODO Hyperparameters
    -   TODO Understand what a hyperparameter is (LL2)
    -   TODO How a hyper-parameter effects model output (LL2)
    -   TODO Understand that hyperparameters can be tuned (LL2)
    
## Thank you! {background-image="/media/daim/bg_cubes_blue_right.png" background-opacity="0.4"}

Any questions?